{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Data Science for Non-Profit Fundraising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data science can be leveraged for non-profit fundraising by using models to predict donors for the current year. Analytics could also help identify cohorts and characteristics of potential donors. The aim of this project is to use an anonymized dataset to predict which constituent will donate in the current fiscal year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This report will be laid out in several steps:\n",
    "\n",
    "1. Data Preparation: review of the data source and prepping the data for analysis.\n",
    "2. Data Analysis: Using visualization, a preliminary analysis of the constituent base of the dataset.\n",
    "3. Prediction Models: Using 3 different models to attempt to predict who will be a current year donor.\n",
    "4. Summary: Findings from analysis and performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsemi\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (C:\\Users\\dsemi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8576/1010786693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mticker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (C:\\Users\\dsemi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.gridspec as grd\n",
    "import scipy.stats\n",
    "import re\n",
    "from os import path\n",
    "from PIL import Image\n",
    "\n",
    "# for regressions with statsmodels:\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "\n",
    "# for regressions with scikit-learn:\n",
    "import sklearn.linear_model as sklm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, \\\n",
    "                            accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "\n",
    "#for plotting confusion matrix:\n",
    "import scikitplot as skplt\n",
    "\n",
    "#for ordinal logistic regression\n",
    "from mord import LogisticIT\n",
    "\n",
    "#These are utility tools of the DMBA book. \n",
    "from dmba import regressionSummary, exhaustive_search\n",
    "from dmba import backward_elimination, forward_selection, stepwise_selection\n",
    "from dmba import adjusted_r2_score, AIC_score, BIC_score\n",
    "from dmba import classificationSummary, gainsChart, liftChart\n",
    "\n",
    "\n",
    "# for KNN:\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#hyperparameter optimization usng RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was sourced from Kaggle.\n",
    "\n",
    "A 34,000 row sample constituent data set from the book: Data Science for Fundraising.\n",
    "\n",
    "Pawlus, M. Fundraising Data, Version 1. Retrieved December 18, 2022 from https://www.kaggle.com/datasets/michaelpawlus/fundraising-data?select=data_science_for_fundraising_donor_data.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the datasets\n",
    "df = pd.read_csv(\"data_science_for_fundraising_donor_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the variables and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "1. Check and remove duplicates\n",
    "2. Removing irrelevant or duplicate date points\n",
    "3. Change categorical variables to numerical\n",
    "4. Check missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df.duplicated()\n",
    "print('Number of duplicate rows = %d' % (dups.sum()))  # counts the number of True's   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Removing irrelevant or duplicate date points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MEMBERSHIP_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['BIRTH_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['AGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ID','BIRTH_DATE', 'MEMBERSHIP_IND'],\n",
    "        axis=1, inplace=True) ## set axis=0 to remove rows, axis=1 to remove columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed the following features:\n",
    "\n",
    "    ID - Not meaningful\n",
    "    MEMBERSHIP_IND - Not meaningful, only has negative value or null\n",
    "    BIRTH_DATE - redundant with AGE feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Change categorical variables to correct numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ALUMNUS_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PARENT_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HAS_INVOLVEMENT_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EMAIL_PRESENT_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DONOR_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to numerical\n",
    "df['ALUMNUS_IND'] = np.where(df['ALUMNUS_IND'] == \"Y\", 1, 0)\n",
    "df['PARENT_IND'] = np.where(df['PARENT_IND'] == \"Y\", 1, 0)\n",
    "df['HAS_INVOLVEMENT_IND'] = np.where(df['HAS_INVOLVEMENT_IND'] == \"Y\", 1, 0)\n",
    "df['EMAIL_PRESENT_IND'] = np.where(df['EMAIL_PRESENT_IND'] == \"Y\", 1, 0)\n",
    "df['DONOR_IND'] = np.where(df['DONOR_IND'] == \"Y\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "df['ALUMNUS_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Giving= df[['PrevFYGiving', 'PrevFY1Giving', 'PrevFY2Giving', 'PrevFY3Giving', 'PrevFY4Giving', 'CurrFYGiving']].copy()\n",
    "Giving.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove commas\n",
    "df = df.replace(',','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove $\n",
    "df['PrevFYGiving'] = df['PrevFYGiving'].str[1:]\n",
    "df['PrevFY1Giving'] = df['PrevFY1Giving'].str[1:]\n",
    "df['PrevFY2Giving'] = df['PrevFY2Giving'].str[1:]\n",
    "df['PrevFY3Giving'] = df['PrevFY3Giving'].str[1:]\n",
    "df['PrevFY4Giving'] = df['PrevFY4Giving'].str[1:]\n",
    "df['CurrFYGiving'] = df['CurrFYGiving'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to numemrical\n",
    "df['PrevFYGiving'] = df['PrevFYGiving'].apply(pd.to_numeric,errors='coerce')\n",
    "df['PrevFY1Giving'] = df['PrevFY1Giving'].apply(pd.to_numeric,errors='coerce')\n",
    "df['PrevFY2Giving'] = df['PrevFY2Giving'].apply(pd.to_numeric,errors='coerce')\n",
    "df['PrevFY3Giving'] = df['PrevFY3Giving'].apply(pd.to_numeric,errors='coerce')\n",
    "df['PrevFY4Giving'] = df['PrevFY4Giving'].apply(pd.to_numeric,errors='coerce')\n",
    "df['CurrFYGiving'] = df['CurrFYGiving'].apply(pd.to_numeric,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZIPCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90265 is the zipcode for Malibu, CA. As it is the most significant, I will update this attribute to binary fields for in Malibu or not. I chose this split rather than converting each zipcode to states or have each be a separate feature to avoid too many dimensions for later computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MalibuCA'] = np.where(df['ZIPCODE'] == 90265.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "df.loc[df['ZIPCODE'] == 90265]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ZIPCODE'],\n",
    "        axis=1, inplace=True) ## set axis=0 to remove rows, axis=1 to remove columns\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WEALTH_RATING'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for integer encoding for ordinal categorical value\n",
    "ordinal_cols = {\n",
    "        '$1-$24999':8, \n",
    "        '$25000-$49999':7,\n",
    "        '$50000-$99999':6, \n",
    "        '$100000-$249999':5,\n",
    "        '$250000-$499999':4, \n",
    "        '$500000-$999999':3, \n",
    "        '$1000000-$2499999':2,\n",
    "        '$2500000-$4999999':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map new values to attribute\n",
    "df['WEALTH_RATING'] = df['WEALTH_RATING'].map(ordinal_cols).fillna(df['WEALTH_RATING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WEALTH_RATING'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MARITAL_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing misclassed fields and combining those without a rating\n",
    "df= df.replace('Uknown', \"0\")\n",
    "df= df.replace('Unknown', \"0\")\n",
    "df= df.replace('U', \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df['GENDER'] != \"0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AGE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4) Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find columns that have missing values\n",
    "nan_cols = df.loc[:,df.isna().any(axis=0)]\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WEALTH_RATING'] = df['WEALTH_RATING'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({'AGE' : df['AGE'].median()}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change categorical variables to new attributes - will also remove null variables\n",
    "df2 = pd.get_dummies(df, columns=['PREF_ADDRESS_TYPE', 'MARITAL_STATUS', 'GENDER', 'DEGREE_LEVEL', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = df2.loc[:,df2.isna().any(axis=0)]\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new target variable for CurrYrGiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['CurrYrDonor'] = np.where(df2['CurrFYGiving'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['CurrYrDonor'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the age ranges of the constituency base?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AGE'].plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the constituency base is between the ages of 35-45. This is typically the early to mid-career point for many people so they are in their core earning years. This constituency base could be ready to have a qualification visit from a fundraiser to explore thier potential philanthropic interests as their wealth continues to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of the constituents have wealth ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y=\"WEALTH_RATING\", data=df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, most of the constiuents do not have wealth ratings. Of those that do have a rating, they are in the lower range of wealth at 6, which is a score that makes them capable of a gift of fifty to ninety-nine thousand dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many constituents have ever made a gift?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y=\"DONOR_IND\", data=df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the constituent base have made a gift before to the institution. As this is anonymized data, the reason is unclear. Potentially, most constituents were collected through a donation of some kind. Overall, the inclination to give again is high based on past giving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring total giving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the correlation of total giving and age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x='AGE', y='TotalGiving', data=df2, marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the donors with the highest amount of total giving are avobe 80 years of age. However the 3rd highest total giving to the institution is in the 40s. As most people do not give, the correlation is hard to see in this graph.\n",
    "\n",
    "\n",
    "### Let's explore this further by incorporating gender into this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='AGE', y=\"TotalGiving\", hue=\"GENDER\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top three highest donors are female to the institution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's take a look at total giving by age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x='AGE', y='WEALTH_RATING', data=df2, marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most wealthy constituents with a wealth rating of 1 are in the ages of 30-45.\n",
    "\n",
    "### Let's take a look at their gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='AGE', y='WEALTH_RATING', hue=\"GENDER\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the three known most wealthy constiuents are male. Let's take a look if they have ever donated to the institution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='AGE', y='WEALTH_RATING', hue=\"GENDER\", col=\"DONOR_IND\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph shows that the highest total giving are from female donors. This graph shows that the wealthiest female constituents has not donated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many constituents donated last year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LastYrDonor = df2.loc[df2['PrevFYGiving'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LastYrDonor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were a total of 2,289 constituents who made a gift last year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many have donated so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrYrDonor = df2.loc[df2['CurrFYGiving'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrYrDonor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,845 donors have so far donated this year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there any new donors to the institution? Are current year donors the same as last year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New = df2.loc[(df2['PrevFYGiving'] == 0) & (df2['CurrFYGiving'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,689 people that have donated this year but not last year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation heatmap \n",
    "corrmat = df2.corr()\n",
    "sns.heatmap(corrmat, square = True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest correlated features are between the giving features.\n",
    "\n",
    "Reviewing how current fiscal year giving correlates to other giving features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df2, y_vars=['CurrFYGiving'], x_vars=['TotalGiving', 'PrevFYGiving', 'CON_YEARS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing how wealth rating correlates to giving features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df2, y_vars=['WEALTH_RATING'], x_vars=['TotalGiving', 'PrevFYGiving','CON_YEARS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the box plot above, there are some donors who have made sizeable gifts that have no wealth rating. This could be a discovery list to confirm their capacity to donate. \n",
    "\n",
    "### Let's identify a discovery pool with anyone that is unrated and has total giving of over or equal to one hundred thousand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery = df2.loc[(df2['TotalGiving'] >= 100000) & (df2['WEALTH_RATING'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 46 total that have total giving of $100,000 or more that have no wealth rating. This should be reviewed internally. The table above shows many that are in the age range where future gifts are possible. A wealth rating could help inform the strategic plan to cultivate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepping predictor and target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the features in the final dataframe to be potential predictor variables. I am removing features that contain giving information that could leak information on what our model is trying to predict such as total giving, consecutive years of giving, donor indicator, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing attributes that have giving information to avoid leakage to the data.\n",
    "X = df2.drop(columns=['CurrFYGiving', 'TotalGiving', 'CON_YEARS', 'DONOR_IND', 'CurrYrDonor'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final list for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable will be a binary feature that was created. It is defined as 1 for made a git this year and 0 as has not made a gift this year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['CurrYrDonor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking sizes of variables are the same\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check balance of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class is imbalanced, so stratify the data when splitting for train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data for performance evaluation with 25% test size and stratified for imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inital model\n",
    "lreg=sklm.LogisticRegression(solver='liblinear')\n",
    "lreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_predictions_tr =lreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the predicted probabilities in training:\n",
    "lreg_predict_prob_tr=lreg.predict_proba(X_train) # predictions for training set as probability values\n",
    "lreg_predict_prob_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_result_tr = pd.DataFrame({'actual': y_train, \n",
    "                             'p(0)': [p[0] for p in lreg_predict_prob_tr],\n",
    "                             'p(1)': [p[1] for p in lreg_predict_prob_tr],\n",
    "                             'predicted': lreg_predictions_tr })\n",
    "print(\"Predicted probabilities of training data\")\n",
    "logit_result_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Highest probability of being a donor from training data\")\n",
    "\n",
    "logit_result_tr.sort_values(by='p(1)', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lowest probability of being a donor from training data\")\n",
    "logit_result_tr.sort_values(by='p(1)').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_train, lreg_predictions_tr, figsize=(4,4), cmap=\"Blues\")\n",
    "plt.title('Confusion matrix of lreg on train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report for training\n",
    "print(\"Classification Report for lreg train:\\n\",classification_report(y_train, lreg_predictions_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance on test data\n",
    "lreg_predictions_tt=lreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test, lreg_predictions_tt, figsize=(4,4), cmap=\"Greens\")\n",
    "plt.title('Confusion matrix of lreg on test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report for lreg test:\\n\",classification_report(y_test, lreg_predictions_tt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of model on test model is much lower than on train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowering the probability for model from default of 50% to 5% to see if the model is able to capture more donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = lreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = probabilities > 0.05\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_test, prediction, figsize=(4,4), cmap=\"Greens\")\n",
    "plt.title('Confusion matrix of 5% lreg on test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report of 5% lreg on test:\\n\",classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 5% probability, the model makes many more mistakes on who is a donor, but it also correctly identifies 367 donors. This could be preferable to capture potential donors. There should be a review on the negative effects of soliciting a donor that is unlikely to donate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a penalty and cross-validation to see if model can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization\n",
    "logitcv = sklm.LogisticRegressionCV(penalty=\"l1\", solver='liblinear', cv=5)\n",
    "logitcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test, logitcv.predict(X_test), figsize=(4,4), cmap=\"Greens\")\n",
    "plt.title('Confusion matrix of l1 lreg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no improvement from the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nominal Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlogit = sklm.LogisticRegression(penalty=\"l2\", solver='lbfgs', C=1e24, multi_class='multinomial')\n",
    "nlogit.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = nlogit.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y, nlogit.predict(X), figsize=(4,4), cmap=\"Blues\")\n",
    "plt.title('Confusion matrix of l2 lreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\",classification_report(y, nlogit.predict(X), zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we scale the Xvar before using KNN:\n",
    "X=preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside 25% of data for out-of-training-sample test:\n",
    "X3pc_train, X3pc_test, Y3pc_train, Y3pc_test = train_test_split(X, y, \\\n",
    "                                                           test_size=0.25, random_state=7)\n",
    "print(X3pc_train.shape, Y3pc_train.shape)\n",
    "print(X3pc_test.shape, Y3pc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters of the KNN classifer:\n",
    "knn_ccv = KNeighborsClassifier(n_neighbors=4, weights='uniform') # considering 4 nearest neighbors weighted equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the KNN model with training data:\n",
    "knn_ccv.fit(X3pc_train, Y3pc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction of the KNN training\n",
    "knn_prediction_ctr=knn_ccv.predict(X3pc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(Y3pc_train, knn_prediction_ctr, figsize=(4,4), cmap=\"Blues\")\n",
    "plt.title('Confusion matrix of knn train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate how good the knn classification of training data is:\n",
    "cm_knn = confusion_matrix(Y3pc_train, knn_prediction_ctr)\n",
    "\n",
    "print(\"Classification Report of knn train:\\n\",classification_report(Y3pc_train, knn_prediction_ctr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate how good the knn classification, after cross-validation:\n",
    "cvparam = KFold(3, random_state=13, shuffle=True)\n",
    "scores_accuracy_knn =  cross_val_score(knn_ccv, X3pc_train, Y3pc_train, cv=cvparam, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_accuracy_knn.mean() #average training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How good is the trained model for predicting the test data?\n",
    "knn_prediction_ctr_tt=knn_ccv.predict(X3pc_test) #use test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(Y3pc_test, knn_prediction_ctr_tt, figsize=(4,4), cmap=\"Greens\")\n",
    "plt.title('Confusion matrix of knn test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate how good the knn classification of training data is:\n",
    "cm_knn_tt = confusion_matrix(Y3pc_test, knn_prediction_ctr_tt)\n",
    "print(\"Classification Report knn on test:\\n\",classification_report(Y3pc_test, knn_prediction_ctr_tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameter optimization\n",
    "\n",
    "params = {\n",
    "     'max_depth': [1, 2, 3, 4, 5],\n",
    "     'learning_rate': [0.1, 0.01, 0.05],\n",
    "     'min_child_weight': [1, 3, 5, 7],\n",
    "     'colsample_bytree': [ 0.3, 0.4, 0.5, 0.7],\n",
    "     'gamma': [0, 0.25, 1.0, 1.5],\n",
    "     'reg_lambda': [0, 1.0, 10.0],\n",
    "     'scale_pos_weight': [1, 3, 5, 7] # NOTE: XGBoost recommends sum(negative instances) / sum(positive instances)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time =datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=xgboost.XGBClassifier(objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start_time=timer(None)\n",
    "random_search.fit(X,y)\n",
    "timer(start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb=xgb.XGBClassifier(seed=42,\n",
    "                          objective='binary:logistic',\n",
    "                          gamma=1.5,\n",
    "                          learning_rate=0.1,\n",
    "                          max_depth=4,\n",
    "                          reg_lambda=1.0,\n",
    "                          scale_pos_weight=7,\n",
    "                          subsample=0.9,\n",
    "                          colsample_bytree=0.4,\n",
    "                          use_label_encoder=False)\n",
    "\n",
    "clf_xgb.fit(X_train, \n",
    "            y_train, \n",
    "            verbose=True, \n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric='aucpr',\n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_xgb, \n",
    "                      X_train, \n",
    "                      y_train,\n",
    "                      values_format='d',\n",
    "                      cmap=\"Blues\",\n",
    "                      display_labels=[\"Did not donate\", \"Donated\"])\n",
    "plt.title('Confusion matrix of XGB train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_xgb, \n",
    "                      X_test, \n",
    "                      y_test,\n",
    "                      values_format='d',\n",
    "                      cmap=\"Greens\",\n",
    "                      display_labels=[\"Did not donate\", \"Donated\"])\n",
    "plt.title('Confusion matrix of XGB test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(clf_xgb)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cumulative_curve(model, scale=100):\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get the probability of Y_test records being = 1\n",
    "    Y_test_probability_1 = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Sort theseprobabilities and the true value in descending order of probability\n",
    "    order = np.argsort(Y_test_probability_1)[::-1]\n",
    "    Y_test_probability_1_sorted = Y_test_probability_1[order]\n",
    "    Y_test_sorted = np.array(y_test)[order]\n",
    "\n",
    "    # Build the cumulative response curve\n",
    "    x_cumulative = np.arange(len(Y_test_probability_1_sorted)) + 1\n",
    "    y_cumulative = np.cumsum(Y_test_sorted)\n",
    "\n",
    "    # Rescale\n",
    "    x_cumulative = np.array(x_cumulative)/float(x_cumulative.max()) * scale\n",
    "    y_cumulative = np.array(y_cumulative)/float(y_cumulative.max()) * scale\n",
    "    \n",
    "    return x_cumulative, y_cumulative\n",
    "\n",
    "def plot_cumulative_curve(models):\n",
    "    # Plot curve for each model\n",
    "    for key in models:\n",
    "        x_cumulative, y_cumulative = build_cumulative_curve(models[key])\n",
    "        plt.plot(x_cumulative, y_cumulative, label=key)\n",
    "    # Plot other details\n",
    "    plt.plot([0,100], [0,100], 'k--', label=\"Random\")\n",
    "    plt.xlabel(\"Percentage of test instances targeted (decreasing score)\")\n",
    "    plt.ylabel(\"Percentage of positives targeted\")\n",
    "    plt.title(\"Cumulative response curve\")\n",
    "    plt.legend()\n",
    "\n",
    "models = {\"Logistic Regression\": lreg,\n",
    "          \"KNN\": knn_ccv,\n",
    "          \"XGBoost\": clf_xgb}\n",
    "plot_cumulative_curve(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lift_curve(models):\n",
    "    # Plot curve for each model\n",
    "    for key in models:\n",
    "        x_cumulative, y_cumulative = build_cumulative_curve(models[key])\n",
    "        plt.plot(x_cumulative, y_cumulative/x_cumulative, label=key)\n",
    "    # Plot other details\n",
    "    plt.plot([0,100], [1,1], 'k--', label=\"Random\")\n",
    "    plt.xlabel(\"Percentage of test instances (decreasing score)\")\n",
    "    plt.ylabel(\"Lift (times)\")\n",
    "    plt.title(\"Lift curve\")\n",
    "    plt.legend()\n",
    "\n",
    "plot_lift_curve(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some key takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data preparation stage, this anonymized dataset is from an institution where a majority of the constituents were densely located in Malibu, CA. The dataset tracks membership, alumnus, parent, and involvement indicators. The majority of the 34,000 rows of data are not members, alumni, parent, or involved. There's an even split between male and female constituents, and the majority are married.\n",
    "\n",
    "Analyzing the data further, most of the constituents are between the ages of 35-45. Nearly 2/3 of the constituents have made a gift in the past and are identified as a donor. Some of the highest total giving at the institution are from those in the ages of 35-45. The highest donors are female, with total giving over $1M. Male constituents with a wealth rating of 1 have previously made a gift to the institution, while the wealthiest female constituent has not made a donation.\n",
    "\n",
    "At the time of this data collection, the institution has eighty percent of the donors that it does from last year, with 1,689 being new donors from last year. This churn is high and implicates that predicting returning donors could be difficult.\n",
    "\n",
    "There is an opportunity to rate donors who have already given to the institution by identifying those with high giving and no wealth rating. This will help inform the strategic plan to cultivate these donors further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting donors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting current year donors with the available features was a difficult task, given the imbalance of donors to non-donors.\n",
    "\n",
    "While most models were overall accurate at 94%+ on average, they all failed to appropriately identified donors by mostly classifying everyone as a non-donor. This proved even more difficult when testing generalization on the test dataset.\n",
    "\n",
    "Sacrificing overall accuracy, a logistic regression with a lower probability could identify more true donors but misclassifying non-donors as donors. An overall cutoff and cost benefit analysis could help determine if this model would be helpful in outreach such as mailings, event invitations, calls, or visits from fundraisers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the poor performance of the models to predict donors, more data and information, especially around past giving could be helpful as the giving features were the highest correlated variables. The challenge with this classification task will continue to be the imbalance of the dataset. With a larger dataset, the model could also have a better opportunity to learn  patterns that increase performance to correctly classify donors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
